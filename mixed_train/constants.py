N_CTX = 512
EPOCHS = 10
BATCH_SIZE = 512
MICROBATCH_SIZE = 8

D_MODEL = 1024
LATENT_DIM = 2048

# Which pretrained model to start from?
MODEL_PATH = "roberta-large"

LR_RAMP_STEPS = 400
LR_DECAY_STEPS = 1378696/BATCH_SIZE
LEARNING_RATE_INIT = 5e-5
LEARNING_RATE_TARGET = 1e-6

LOG_INTERVAL = 2
CHECKPOINT_INTERVAL = 15
VALIDATE_INTERVAL = 50
VALIDATION_SIZE = 1000

LOAD_CHECKPOINT = False
DO_VALIDATE = True
DO_LOG = False
USE_BUCKET = False
