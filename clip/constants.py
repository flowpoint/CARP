
EPOCHS = 10
BATCH_SIZE = 4
MICROBATCH_SIZE = 2 # If batch size is too much for mem

# Size of encodings
LATENT_DIM = 2048

# Size of GPT embedding (n_feat from gpt2)
GPT_OUT = 1536

# training
LEARNING_RATE = 1e-4
